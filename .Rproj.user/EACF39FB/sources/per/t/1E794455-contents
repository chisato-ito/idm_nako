---
title: "MET3 - Propensity Score Analysis: R-labs"
author: "Ricarda Schulz, Rodrigo Huerta Guti√©rrez de Velasco, and Tobias Kurth"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: spacelab
    toc: true
    toc_depth: 6
    toc_float: true
  smooth_scroll: true 
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

------------------------------------------------------------------------

# R-labs

## Lab 1

### Clinical example {.tabset}

Tissue plasminogen activator (t-PA) and risk of in-hospital mortality among patients with ischemic stroke.

In the early 2000s, despite recent advances, the treatment of acute ischemic stroke remained challenging. Therapy with tissue plasminogen activator (t-PA) has been shown to be successful in reducing the functional outcome from ischemic stroke.

From 3 RCTs, we know that there is no association between t-PA and death in patients with acute ischemic stroke. The relative risk estimates in these trials ranged from 0.85-1.17, and the pooled Mantel-Haenszel estimate is 1.16 (95%CI; 0.95-1.43). Besides, observational studies from community hospitals showed increased relative risks of death after t-PA therapy (about 2-fold).

#### Objective

To estimate the effect of t-PA treatment and risk of in-hospital mortality among patients with acute ischemic stroke in an observational setting.

#### Data

-   Originate from Westphalian Stroke Register: regional data bank in the northwest of Germany

-   On a voluntary basis, 24 neurological, 13 internal medicine and 5 geriatric medicine departments in 42 hospitals participated in the project in 2000 and 2001

-   Included patients treated for a transient ischemic attack, ischemic stroke or intracerebral hemorrhage

-   Sociodemographic characteristics, cerebrovascular risk factors, comorbidities, stroke type and severity, as well as details regarding the participating centers, the mode of admission, diagnostic and therapeutic procedures and complications documented

-   The standardized data assessment forms were evaluated centrally at the Institute of Epidemiology and Social Medicine at the University of Muenster, Germany

-   In total, 12,410 patients with stroke symptoms were entered into the registry until 2001: 8,208 were ischemic, 2,794 transient ischemic attacks, 793 primary intracerebral hemorrhages and 615 unknown

-   For this clinical example, only ischemic stroke patients were considered. Furthermore, ischemic stroke patients were excluded from centers that did not perform t-PA lysis throughout the time of observation (2000-2001)

-   A total of 6,269 patients were included in the original example. More details of the original sample can be found: Kurth T et al. Results of multivariable logistic regression, propensity matching, propensity adjustment, and propensity-based weighting under conditions of nonuniform effect. Am J Epidemiol. 2006 Feb 1;163(3):262--70.

The data set we use in this lab is a **randomly modified dataset**. Therefore, some of the association pattern behaves differently than clinically expected. The total number of observations in this dataset is set to 10,000.

This data set is for your **personal use only**. Please do not share it outside of class.

------------------------------------------------------------------------

#### Load the packages

This part reads in the necessary R packages that are needed to run the code.

------------------------------------------------------------------------

```{r}

#In this chunk, we install the packages required for our analysis.

#First, we delete the objects in the R-environment:
rm(list=ls())

#We create a list of packages needed to perform our analyses: 
packages <- c("ggplot2", "arsenal", "samplesizeCMH", "dplyr", "MatchIt", "sas7bdat", "table1", "devtools", "haven", "tidyverse", "cobalt", "knitr", "rmarkdown","pROC", "purrr", "janitor", "magrittr", "expss", "broom.helpers", "geepack")

#We tell R, to install packages if they are not yet installed:
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

#Load packages:
invisible(lapply(packages, library, character.only = TRUE))

#If you can't install packages in bulk, try to install manually or from the developer site (see below for an example).

## install.packages("arsenal")
## library(arsenal)

```

------------------------------------------------------------------------

#### Reading in the data

```{r}

#We set the working directory to where the dataset is stored:
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

#Reading in the data:  
datab <- read.sas7bdat("../data/pscore_data_new.sas7bdat")
 
#Alternatively, select the data file from wherever you have stored it

names(datab) <- tolower(names(datab)) #to "de-capitalize" variable names within the dataset

```

------------------------------------------------------------------------

#### Data set pre-processing and structure

```{r}

#We create a vector of variables out of our dataset that will be used within our analysis: 
myvars <- c("age", "afib", "aphasia", "cardiac", "sex", "htn", "hyperchol", "icu", "living",  "rankpre", "residentq", "referral", "paresis", "prevstroke", "sumbart90", "transport", "vigilanz", "ward", "timeintcat", "year", "tpa", "age70", "death", "comorbid", "stunit", "id", "age5")

#As we perform a complete case analysis, we have to restrict our dataset to complete cases: 
datab <- datab %>%
  select(c(myvars)) %>% 
  filter(complete.cases(.))


# We also create labels to levels of variables:
datab <- apply_labels(datab,
                      tpa = "Tissue plasminogen activator (tPA)",
                      tpa = c("tpa treatment" = 1, "no tpa treatment" = 0),
                      sex = "Sex",
                      sex = c("Unknown" = 0, "Male" = 1, "Female" = 2),
                      paresis = "Paresis",
                      paresis = c("No" = 0, "Monoparesis" = 1, "Hemiplegia" = 2, 
                                  "Tetraplegia" = 3),
                      aphasia = "Aphasia",
                      aphasia = c("No" = 0, "Yes" = 1),
                      comorbid = "Comorbidity",
                      comorbid = c("Yes" = 1, "No" = 0),
                      hyperchol = "Hypercholesterolemia",
                      hyperchol = c("No" = 0, "Yes" =1),
                      prevstroke = "Prevalent stroke",
                      prevstroke = c("Yes" = 1, "No" = 0),
                      afib = "Atrial fibrillation",
                      afib = c("Yes" = 1, "No" = 0))

#In the following step we need to factor some of the variables, as they are factorial.

#Vector of factor vars 
factor.vars <- c("age5", "afib", "aphasia", "cardiac", "sex",
                 "htn", "hyperchol", "icu", "living", "rankpre", 
                 "residentq", "referral", "paresis", "prevstroke", "sumbart90", "timeintcat","transport", "vigilanz", "ward","year")

#Mapping the factor function to the vector of vars
datab <- datab %>%  
  modify_at(factor.vars, factor)

#Check var type
str(datab[factor.vars]) 

#Check labels
table(datab$paresis)

```

```{r}

#We want to get an idea about the structure of the dataset:
summary(datab)
str(datab, give.attr= FALSE)
apply(datab, 2, FUN= summary, nmiss)

```

------------------------------------------------------------------------

#### Study population and outcomes

-   10,000 ischemic stroke patients included

-   328 (3.3%) were treated with t-PA

-   Of the patients treated with t-PA, 52 (15.9%) died during the hospital course compared to 543 (5.9%) in the group not treated with t-PA

-   Many covariates differed with respect to exposure status

------------------------------------------------------------------------

### Data analysis

#### Crude association between exposure and outcome

#### Logistic regression model

```{r}

#We create a 2x2 table between the treatment and the outcome: 
two_by_two <- table(datab$tpa, datab$death)

two_by_two%>%
  as.data.frame.matrix() %>%
  tibble::rownames_to_column() %>%
  adorn_totals(name = 'total') %>%
  adorn_totals(name = 'total', where = 'col')

#Now, we build a basic logistic model with death as the dependent variable and tpa as the only independent variable:
mod <- glm (death ~ tpa, data= datab, family="binomial")

#Get Odds Ratio (OR) and 95% Confidence Intervals (CIs) 
mod %>% 
  tidy_and_attach(exp= TRUE, conf.int= TRUE) %>%
  tidy_add_n() %>% 
  knitr::kable("pipe", digits= 3)

```

------------------------------------------------------------------------

#### Table 1

(1) **Discuss the extent to which the two groups are similar in their characteristics (or not) What does that mean?**

```{r, results = 'asis'}

#By applying the following code, we will create our Table 1
tableby(tpa ~ age + sex + paresis + aphasia + comorbid + stunit + prevstroke + hyperchol + rankpre + afib, data= datab) %>% 
  summary(test= FALSE, total= TRUE, digits=3)

```

------------------------------------------------------------------------

#### Age-adjusted model


```{r}

#Logistic regression of the exposure-outcome effect, controlling for confounding.

#First, we build an outcome model, adjusted for age
model1 <- glm (death ~ tpa + age, data= datab, family= "binomial")

#Get number of observations and events
model1 %>% 
  tidy_and_attach(exp= TRUE, conf.int= TRUE) %>%
  tidy_add_n() %>% 
  knitr::kable("pipe", digits= 3)

```

------------------------------------------------------------------------

#### Multivariable adjusted model

(2) **After multivariable adjustment, did the effect estimate of tPA change? If yes, what do you think is the reason?**

```{r}
#Now, we fit a multivariable model:
model1a <- glm(death ~ tpa + age + afib + aphasia + cardiac + sex + htn + hyperchol + icu + living + rankpre + residentq + referral + paresis + prevstroke + sumbart90 + transport + vigilanz + ward + timeintcat + year, data=datab, family="binomial")

#Get OR and 95% CIs:
model1a %>% 
  tidy_and_attach(exp = TRUE, conf.int = TRUE) %>%
  
  tidy_add_n()%>% 
  knitr::kable("pipe", digits= 3)
```

------------------------------------------------------------------------

#### Multivariable model with time covariate interaction

```{r}

#We fit a multivariable model with time covariate interaction:
model2 <- glm(death ~ tpa + age + afib + aphasia + cardiac + sex + htn + hyperchol + icu + living + rankpre + residentq + referral + paresis + prevstroke + sumbart90 + transport + vigilanz + ward + timeintcat + year + timeintcat:year + age70:year, data=datab, family="binomial")

#Get OR and 95% CIs:
model2 %>% 
  tidy_and_attach(exp = TRUE, conf.int = TRUE) %>%
  
  tidy_add_n()%>% 
  knitr::kable("pipe", digits= 3)

```

(3) **Would you present or interpret the whole table with the covariates and estimates listed as part of your manuscript? Why or why not?**

------------------------------------------------------------------------

## Lab 2

### Propensity Score model example

[Remember]{.ul}: the propensity score can be estimated by building a multivariable regression model that predicts treatment A=1. The selection of variables to be included in the propensity score model involves both predictors of treatment and risk factors for the outcome. All have to be pre-treatment variables since controlling for a consequence of treatment could introduce a bias (i.e., collider stratification bias). Interactions between the predictors of treatment could also be considered. The a prior selection of covariates included in this propensity score example is the result of discussions between clinicians and epidemiologist and are based on causal thinking.

### Propensity Score model

```{r}

#In this step we now build the propensity score model:
model3 <- glm(tpa ~ age + afib + aphasia + cardiac + sex + htn + hyperchol + icu + living + rankpre + residentq + referral + paresis + prevstroke + sumbart90 + transport + vigilanz + ward + timeintcat + year + timeintcat:year + age70:year,data=datab,family="binomial")

#Get number of observations and events
model3 %>% 
  tidy_and_attach(exp= TRUE, conf.int= TRUE) %>%
  tidy_add_n() %>% 
  knitr::kable("pipe", digits= 3)

#Now we add a variable to the data with the PS:
datab$pscore[as.numeric(names(fitted(model3)))] <- fitted(model3)

#Basic statistics by tpa
options(scipen = 9)
aggregate(pscore ~ tpa, data= datab, FUN= summary)

```

------------------------------------------------------------------------

### Propensity Score diagnostics

```{r}

#Get minimum, median, mean, and maximum of the propensity scores within the dataset:
summary(datab$pscore)

#We want to get insights into the distribution of the propensity score among patients that were treated with tpa and those who did not:
tableby(tpa ~ pscore, data=datab, numeric.stats=c("Nmiss","meansd", "median", "q1q3", "range"))%>%
  summary(test=FALSE, total=TRUE, digits=2)

#Graphing propensity score distributions in the treated vs. the untreated
ggplot(datab, aes(x=pscore, group=factor(tpa), fill=factor(tpa)))+
  geom_density(alpha=0.3) +
  scale_fill_manual(values =c("#E69F00", "#607b8b"))+
  labs(x = "Propensity Score", y = "Density", fill = "TPA")
                    
```

(4) **When looking at the propensity score diagnostics and the plot, what are your thoughts or concerns?**

### C-statistic: propensity score model

[Remember]{.ul}: the c-statistic is an instrument to assess the discriminative ability of a model. The discriminative ability is the probability that one participant drawn from the event group (in our cased, the treated) has a higher predicted risk estimated by the model compared to one participant drawn from the group without the event (in our case the untreated).

The c-statistic will range between 0.5, indicating a model that performs no better than chance at predicting therapy, and 1.0, indicating a model that is perfectly able to correctly discriminate the two groups. A higher c-statistic indicates more discrimination but it depends on the purpose of the model whether this indicates a better model.

```{r}

#Calculating the area under the curve (AUC):
auc(roc(model3$y, predict(model3,type="response")))

```

(5) **Please interpret the AUC.**

------------------------------------------------------------------------

### Regression adjusted for the propensity score grouped by quintiles

```{r}

#In this step we generate quintiles of the propensity score:
datab$ps_cat <- cut(datab$pscore, breaks=quantile(datab$pscore, probs=seq(0,1,by=0.20)), 
                   include.lowest = T, right = T)

#Tabulate results:
table(datab$ps_cat)

```

```{r}

#Fit logistic regression model with PS grouped by quintiles as independent variable: 
model4 <- glm(death ~ tpa + ps_cat,
            family = binomial(link="logit"),
            data = datab)

#Provide summary of results:
summary(model4)

#Get number of observations and events, OR and 95 %CI
model4%>% 
  tidy_and_attach(exp = T, conf.int = T) %>%
  tidy_add_n() %>% 
  knitr::kable("pipe", digits= 3)

```

###Stratified analysis by propensity score quintiles

```{r}

##  2x2 tables of exposure-outcome in each PS quintile group
strat_tables <- table(datab$tpa, datab$death, datab$ps_cat, 
                  dnn=c("TPA","Death","PS_cat"))

strat_tables

apply(strat_tables, 3, odds.ratio)

addmargins(strat_tables)

```

Adjusted OR, 95% CI, Mantel-Haenszel estimator

```{r}

#We estimate the adjusted OR, 95% CI, and the Mantel-Haenszel estimator:
mantelhaen.test(strat_tables)

```

------------------------------------------------------------------------

### Propensity score matching

[Remember]{.ul}: matching on the propensity score will remove, in *expectation*, confounding by factors considered in the propensity score model. In a matched cohort study, confounding is removed by the matching factor, as the distribution of the matching factor will be similar in the treatment groups.

#### Greedy nearest neighbor matching without replacement

The greedy nearest neighbor algorithm selects a treated subject and then selects a matched control subject. It selects the untreated subject whose propensity score is closest to that of the treated subject. If multiple untreated subjects are equally close to the treated subject, one of these untreated subjects is selected at random.

Note: Greedy nearest neighbor matching may result in poor quality matches overall: the first few matches might be good matches, and the rest poor matches because one match at a time is optimized instead of the whole system.

Matching without replacement (as applied in this example):

\- Remove matched pairs from the data set

\- Keep on matching until no more matches based on criteria are found

```{r}

# We match on the PS:
pscoreMatch <- matchit(formula= tpa ~ age + afib + aphasia + cardiac + sex + htn + hyperchol + icu + living + rankpre + residentq + referral + paresis + prevstroke + transport + vigilanz + ward + timeintcat:year + age70:year,
                       data=datab,
                       distance="logit",#the distance argument states which model is going to be used to calculate the propensity score
                       method="nearest",#the method argument is used to select a matching procedure. in this case the greedy method, nearest neighbor matching is used.
                       replace= FALSE, #this argument is set to false, as we do not want replacement 
                       caliper= 0.05) 

summary(pscoreMatch, un= FALSE)#un=FALSE avoids the display of the balance before matching 

```

(6) **What does "nearest" mean in the context of the matching procedure?**

(7) **What does "replace = FALSE" mean in the context of the matching procedure?**

(8) **What happens if one sets the caliper to 0.1?**

```{r}

#We create a love plot. A love plot graphically displays the covariate balance
love.plot(bal.tab(pscoreMatch, m.threshold= 0.2),
                       stats="mean.diffs",
                       grid= TRUE,
                       stars="raw",
                       abs= FALSE,
                       sample.names= c("unmatched","matched"),
                       colors =c("#E69F00", "#607b8b"))

#extract matched sample
m.data <- match.data(pscoreMatch)

#look at the matched cohort data
#View(m.data)

```

(9) **Describe what we achieved by the matching by visually examining the covariate balance depicted by the love plot.**

#### Distribution of the propensity score in the matched cohort

```{r, results='asis'}

#Distribution of the propensity score for people treated with t-PA and those who were not within the matched cohort.

#We create a table 
tableby(tpa ~ pscore, data=m.data,
        numeric.stats=c("Nmiss", "meansd", "median", "q1q3", "range"))%>%
  summary(test= FALSE, total= TRUE,digits=2)

#We visualize the distribution of the propensity score in the matched dataset
ggplot(m.data, aes(x= pscore, group=factor (tpa),
fill= factor (tpa)))+
    geom_density(alpha= 0.5)+
    scale_fill_manual(values =c("#E69F00", "#607b8b"))+
    labs(x = "Propensity Score", y = "Density", fill = "TPA")

```

(10) **Describe the distribution of the propensity score in the matched dataset using your own words.**

#### Table 1 - matched cohort

```{r, results='asis'}

# Table with confounding variables by exposure for matched individuals 
tab2 <- tableby(tpa~ age + sex+ paresis + aphasia + comorbid + stunit + hyperchol+ prevstroke + rankpre + afib, data= m.data)

#tab2
summary(tab2, test= FALSE, total= TRUE, digits=2)

```


#### Adjusted logistic regression model - matched cohort

```{r}

#Model on the PS-matched subset:
model5 <- glm (death~ tpa, family= binomial (link= "logit"), data=m.data)

#Get number of observations, events, the OR and 95% CIs:
model5 %>% 
  tidy_and_attach(exp= TRUE, conf.int= TRUE) %>%
  tidy_add_n()%>% 
  knitr::kable("pipe", digits= 3)

```

(11) **Does the effect estimate for tPA differ from the multivariable model? If yes, what do you think is the reason?**

[Remember]{.ul}: matched analyses estimate the average treatment effect of the treated (ATT).

## Lab 3

### Inverse Probability of Treatment Weighting (IPTW) and Standardized Mortality Ratio (SMR)

The individuals within our study population are now going to be copied based on a weight calculated from the propensity score. The new study population is referred to as pseudo-population. The weights copy individuals based on the confounder history.

#### IPTW with unstabilized weights

-   In the treated group the weight is 1/![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*

-   In the untreated group the weight is 1/1-(![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*)

-   Using unstabilized weights, we end up with a pseudo-population that is larger than the original study population. The mean of the total weights should ideally be 2.

-   IPTW is estimating the marginal treatment effect (i.e., the contrast of treating all patients compared to treating no one). Hence, IPTW is estimating the average treatment effect (ATE)

```{r, results='asis'}

#Estimating unstabilized inverse probability weights: 
datab$w1 <- ifelse(datab$tpa==1,
                   1/datab$pscore,
                  1/(1-datab$pscore))

#We check if it worked: 
#View(datab)

#head(datab, 10) %>% 
  #knitr::kable(format = "pipe")

#We get the diagnostics of the weights: 
tableby(tpa~w1, data=datab, numeric.stats=c("Nmiss","meansd","median","q1q3","range"))%>%
  summary(test=FALSE, total=TRUE, digits=2)

```

##### Logistic regression IPTW unstabilized weights

```{r}

#logistic regression model with unstabilized weights 
model6 <- glm(death ~ tpa, family= binomial (link="logit"),data=datab,weights= w1)

#Results from model
summary(model6)

 
model6.1 <- geeglm(death ~ tpa, data=datab,weights= w1,
            id = id, corstr = "independence", family = binomial)

#Results from model with robust SE
summary(model6.1)

```

###### Adjusted OR, 95% CI

```{r, results="asis"}

##Format estimates into tibble and get number of observations, events, OR and 95% CIs:
model6 %>% tidy_and_attach(exp = TRUE, conf.int = TRUE) %>% tidy_add_n() %>% knitr::kable("pipe",digits= 3)

model6.1 %>% tidy_and_attach(exp = TRUE, conf.int = TRUE) %>% tidy_add_n() %>% knitr::kable("pipe",digits= 3)

```

##### Balance plot - IPTW unstabilized weights

```{r}

#We create a balance plot in the pseudo-population: 
balance1 <- bal.tab(factor(tpa) ~ age + sex + paresis + aphasia + comorbid + hyperchol + stunit + prevstroke + rankpre + afib , data = datab, weights = "w1", un = TRUE)

 
love.plot(balance1, thresholds = c(m = .2),
          stats = "mean.diffs",
          grid = TRUE,
          stars = "raw",
          abs = FALSE, 
          colors =c("#E69F00", "#607b8b")) 
  
```

#### IPTW with stabilized weights

-   In the treated group the weight is: P(A=1)/![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*

-   In the untreated group the weight is: P(A=0)/1-(![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*)

-   Using stabilized weights preserves the sample size of the original study sample. The mean of the total weights should ideally be 1.

```{r, results='asis'}

#We estimate the stabilized inverse probability weights: 
datab$w2 <- ifelse(datab$tpa==1,
                   mean(datab$tpa)/datab$pscore,
                   (1-mean(datab$tpa))/(1-datab$pscore))

#If you want to check the dataset for stabilized weights "un-comment" the line below: 
#View(datab)

#Diagnostics of the stabilized weights: 
tableby(tpa~w2, data=datab,
        numeric.stats= c("Nmiss", "meansd", "median", "q1q3", "range")) %>% 
  summary(test=FALSE, total= TRUE, digits= 2)

```

##### Logistic regression IPTW stabilized weights

```{r}

#We build a logistic regression model with stabilized weights: 
model7 <- glm(death ~ tpa, family= binomial (link= "logit"), data=datab,weights= w2)


#Get OR and 95% CIs:
broom::tidy(model7, exp= TRUE, conf.int= TRUE) %>% 
  knitr::kable("pipe", digits= 3)

#Get number of observations and events:
model7 %>% 
  tidy_and_attach(exp = TRUE, conf.int = TRUE) %>%
  tidy_add_n()

```

##### Balance plot - IPTW stabilized weights

```{r}

#We create a balance plot in the pseudo-population:
balance2 <- bal.tab(factor(tpa) ~ age + sex + paresis + aphasia + comorbid + hyperchol + stunit + prevstroke + rankpre + afib, data = datab, weights = "w2", un = TRUE)

love.plot(balance2, thresholds = c(m = .2),
          stats = "mean.diffs",
          grid = TRUE,
          stars = "raw",
          abs = FALSE,
          colors =c("#E69F00", "#607b8b")) 

```

#### SMR weights

-   In the treated group, the weight is 1

-   In the untreated group, the weight is ![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*/1-(![\\pi](https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a){width="8" height="10"}*(L)*)

-   The pseudo-population is smaller compared to the original study population. We end up with a standardized estimator with the treated group as the target population. Hence, we are estimating the average treatment effect on the treated (ATT).

```{r, results='asis'}

#We estimate SMR weights: 
datab$w3 <- ifelse(datab$tpa==1,
                   1,
                   datab$pscore/(1-datab$pscore))

#f you want to check the dataset for SMR weights "un-comment" the line below:
#View(datab)

#Diagnostics of SMR weights: 
tableby(tpa ~ w3, data=datab,
        numeric.stats=c("Nmiss", "meansd", "median", "q1q3", "range"))%>%
  summary(test= FALSE, total= TRUE, digits=2)

```

##### Logistic regression SMR weights

```{r}

#Logistic regression model with SMR weights: 
model8 <- glm(death ~ tpa, family= binomial (link="logit"), data=datab,weights= w3)

#Get OR and 95% CIs
broom::tidy(model8, exp= TRUE, conf.int= TRUE) %>% 
  knitr::kable("pipe", digits= 3)

#Get number of observations and events
model8 %>% 
  tidy_and_attach(exp = TRUE, conf.int = TRUE) %>%
  tidy_add_n()

```

##### Balance plot SMR weights

```{r}

#We create a balance plot in the SMR pseudo-population 
balance3 <- bal.tab(factor(tpa) ~ age + sex + paresis + aphasia + comorbid + hyperchol + stunit + prevstroke + rankpre + afib , data = datab, weights = "w3", un = TRUE)

love.plot(balance3, thresholds = c(m = .2),
          stats = "mean.diffs",
          grid = TRUE,
          stars = "raw",
          abs = FALSE,
          colors =c("#E69F00", "#607b8b")) 

```

#### Overlap weights

```{r, results='asis'}

#Estimating overlap weights 
datab$w4 <- ifelse(datab$tpa==1,
                   1-datab$pscore,
                   datab$pscore)

#f you want to check the dataset for overlap weights "un-comment" the line below:
#View(datab)

#diagnostic of overlap weights 
tableby(tpa ~ w4, data=datab,
        numeric.stats=c("Nmiss", "meansd", "median", "q1q3", "range"))%>%
  summary(test= FALSE, total= TRUE, digits=2)

```

##### Logistic regression Overlap weights

```{r}

#Logistic regression model with overlap weights 
model9 <- glm(death ~ tpa, family= binomial (link="logit"), data=datab,weights= w4)

#Get OR and 95% CIs
broom::tidy(model9, exp= TRUE, conf.int= TRUE) %>% 
  knitr::kable("pipe", digits= 3)

#Get number of observations and events
model9 %>% 
  tidy_and_attach(exp = TRUE, conf.int = TRUE) %>%
  tidy_add_n()

```

##### Balance plot Overlap weights

```{r}

#We create a balance plot for the overlap weight pseudo-population
balance4 <- bal.tab(factor(tpa) ~ age + sex + paresis + aphasia + comorbid + hyperchol + stunit + prevstroke + rankpre + afib, data = datab, weights = "w4", un = TRUE)

love.plot(balance4, thresholds = c(m = .2),
          stats = "mean.diffs",
          grid = TRUE,
          stars = "raw",
          abs = FALSE,
          colors =c("#E69F00", "#607b8b"))

```

# Take home message

We have observed that different approaches to control for confounding using a traditional logistic regression model and different propensity-score approaches can lead to extremely different results. The difference in results does not prove or even suggest that any of the methods was superior for controlling confounding, but the results are answers to different research questions.

The interpretation of propensity score analyses depends on the underlying assumptions with respect to:

-   Residual confounding

-   Effect heterogeneity

-   Overlap in propensity score distributions between exposed and unexposed

The researcher needs to be clear to which target population the estimate is most suitable.
